
Setup an experiment on Cloudlab using the SparkFHE-Base-Ubuntu18.04 image. Please make note of the master node login.

Also, note that the scripts are designed to run on Master Node.

## Prerequisites
* On all the nodes follow [instructions](https://github.com/SpiRITlab/SparkFHE-Examples/wiki) to setup SparkFHE distribution. Make sure you have gone through all the steps and the mySparkSubmitLocal.bash script runs correctly.

# SSH into Master Node
SSH into address for master node and navigate to the address specified below
```
ssh -p 22 username@id.region.cloudlab.us
cd /spark-3.0.0-SNAPSHOT-bin-SparkFHE/SparkFHE-Addon/scripts/cluster/yarn_cluster_setup
```

# Install Hadoop and Spark on all nodes through Master Node
Specify the names of nodes as arguments.
```
sudo bash install.sh master,worker1,worker2 ...
```

# Start Yarn Spark Cluster and Run Spark Job on Master
```
sudo bash start_yarn_cluster.sh
cd Test_Pi
sudo bash run_spark_job_pi.sh
```
Use the link generated after successful completion of cluster building to view the web interface for Yarn. Other links can be generated by changing the port number.

YARN Interface:

http://master.experiment-name.iotx-pg0.region.cloudlab.us:8088/cluster

Spark Interface:

http://master.experiment-name.iotx-pg0.region.cloudlab.us:8080/

Namenode Interface:

http://master.experiment-name.iotx-pg0.region.cloudlab.us:50070/

Datanode Interface:

http://username.region.cloudlab.us:50075

JobMaster Interface:

http://master.experiment-name.iotx-pg0.region.cloudlab.us:19888/jobhistory

# Stop the Cluster
```
cd ..
sudo bash stop_yarn_job.sh
```
After running this command, the web interfaces will not work.